{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-08T05:05:29.747473Z",
     "start_time": "2024-11-08T05:04:56.457977Z"
    }
   },
   "source": [
    "# import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import Compose, Rotate, RandomResizedCrop, Normalize\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import time\n",
    "from itertools import product\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jerry\\.conda\\envs\\pytorch\\lib\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Data Processing and Augmentation",
   "id": "fe6dd16880d27710"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T05:05:29.763137Z",
     "start_time": "2024-11-08T05:05:29.749473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Transformations for the training and test sets\n",
    "def get_transforms():\n",
    "    train_transform = A.Compose([\n",
    "        A.RandomResizedCrop(height=32, width=32, scale=(0.8, 1.0)),  # Random Resized Crop\n",
    "        A.Rotate(limit=30),  # Random Rotate (Â±30 degrees)\n",
    "        A.OneOf([  # Random Horizontal Flip or Vertical Flip\n",
    "            A.MotionBlur(p=0.2),  # Motion Blur\n",
    "            A.MedianBlur(blur_limit=3, p=0.1),  # Median Blur\n",
    "            A.GaussianBlur(blur_limit=3, p=0.1),  # Gaussian Blur\n",
    "        ], p=0.3),\n",
    "        A.OneOf([  # Random Brightness or Contrast\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "            A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
    "        ], p=0.3),\n",
    "        A.CoarseDropout(max_holes=1, max_height=16, max_width=16, fill_value=0, p=0.5),  # Random Coarse Dropout\n",
    "        A.Resize(32, 32),  # Resize to 32x32\n",
    "        A.Normalize(mean=[0.4377, 0.4438, 0.4728], std=[0.1980, 0.2010, 0.1970]),  # Normalize\n",
    "        ToTensorV2()  # Convert to Tensor\n",
    "    ])\n",
    "    \n",
    "    test_transform = A.Compose([\n",
    "        A.Resize(32, 32),  # Resize to 32x32\n",
    "        A.Normalize(mean=[0.4377, 0.4438, 0.4728], std=[0.1980, 0.2010, 0.1970]),  # Normalize\n",
    "        ToTensorV2()  # Convert to Tensor\n",
    "    ])\n",
    "    \n",
    "    return train_transform, test_transform\n",
    "\n",
    "def load_svhn_data(batch_size, train_transform, test_transform):\n",
    "    # Load the SVHN dataset\n",
    "    train_dataset = datasets.SVHN('./data', split='train', download=True, transform=lambda img: train_transform(image=np.array(img))['image'])\n",
    "    test_dataset = datasets.SVHN('./data', split='test', download=True, transform=lambda img: test_transform(image=np.array(img))['image'])\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, drop_last=True)\n",
    "    \n",
    "    return train_loader, test_loader"
   ],
   "id": "31a0324066b7318",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Neural Network Setup",
   "id": "82dc84ae89bda4be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T05:05:29.931846Z",
     "start_time": "2024-11-08T05:05:29.764136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the VGG model\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, kernel_size=3, padding=1), nn.GroupNorm(2, 8), nn.ReLU(),\n",
    "            nn.Conv2d(8, 16, kernel_size=3, padding=1), nn.GroupNorm(4, 16), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), nn.Dropout(0.25),  # 14x14\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1), nn.GroupNorm(8, 32), nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1), nn.GroupNorm(8, 32), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), nn.Dropout(0.25),  # 7x7\n",
    "\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1), nn.GroupNorm(8, 32), nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1), nn.GroupNorm(8, 32), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), nn.Dropout(0.25)   # 3x3\n",
    "        )\n",
    "\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(32 * 4 * 4, 256), nn.GroupNorm(32, 256), nn.ReLU(),\n",
    "            nn.Dropout(0.5),  # Add Dropout here\n",
    "            nn.Linear(256, 10)  # Output layer (10 classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model, loss function, and optimizer with L2 regularization\n",
    "model = VGG().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# L2 regularization is applied via the 'weight_decay' parameter in the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)"
   ],
   "id": "aeb47c208b8c8837",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. Training and Evaluation Functions",
   "id": "40eeb69b8414d40e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T05:05:29.947548Z",
     "start_time": "2024-11-08T05:05:29.933841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training, evaluation, and helper functions\n",
    "def _train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item() * len(images)\n",
    "    return epoch_loss / len(train_loader.dataset)\n",
    "\n",
    "def _evaluate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_outputs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            epoch_loss += loss.item() * len(images)\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_outputs.extend(outputs.cpu().numpy())\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    epoch_loss = epoch_loss / len(test_loader.dataset)\n",
    "\n",
    "    # Calculate ROC AUC\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_outputs = np.array(all_outputs)\n",
    "    all_labels_one_hot = np.eye(10)[all_labels]\n",
    "\n",
    "    macro_roc_auc = roc_auc_score(all_labels_one_hot, all_outputs, average='macro', multi_class='ovr')\n",
    "    micro_roc_auc = roc_auc_score(all_labels_one_hot, all_outputs, average='micro', multi_class='ovr')\n",
    "\n",
    "    return epoch_loss, accuracy, macro_roc_auc, micro_roc_auc, all_labels, all_outputs"
   ],
   "id": "9849d130a9119238",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4. Analysis of Training and Evaluation(Experiments)",
   "id": "29cc301934030d96"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4.1 Define the ExperimentRunner Class",
   "id": "4f6581c3d950d391"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T05:05:29.962681Z",
     "start_time": "2024-11-08T05:05:29.948548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train the model\n",
    "class ExperimentRunner:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.model = VGG().to(device)\n",
    "        self.loss_function = nn.CrossEntropyLoss()\n",
    "        self.optimizer = self._select_optimizer(config['optimizer'])\n",
    "        \n",
    "        train_transform, test_transform = get_transforms()\n",
    "        self.train_loader, self.test_loader = load_svhn_data(config['batch_size'], train_transform, test_transform)\n",
    "        \n",
    "        self.train_losses = []\n",
    "        self.test_losses = []\n",
    "        self.accuracies = []\n",
    "        self.macro_roc_aucs = []\n",
    "        self.micro_roc_aucs = []\n",
    "        self.class_roc_aucs = []\n",
    "\n",
    "    def _select_optimizer(self, optimizer):\n",
    "        if optimizer == 'adam':\n",
    "            return optim.Adam(self.model.parameters(), lr=self.config['learning_rate'])\n",
    "        elif optimizer == 'sgd':\n",
    "            return optim.SGD(self.model.parameters(), lr=self.config['learning_rate'], momentum=0.9)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown optimizer: {optimizer}\")\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in range(self.config['num_epochs']):\n",
    "            start_time = time.time()\n",
    "            # Train using the _train_epoch function from the first cell\n",
    "            train_loss = _train_epoch(self.model, self.train_loader, self.loss_function, self.optimizer, device)\n",
    "            self.train_losses.append(train_loss)\n",
    "\n",
    "            # Test using the _evaluate function from the first cell\n",
    "            test_loss, accuracy, macro_roc_auc, micro_roc_auc, all_labels, all_outputs = _evaluate(\n",
    "                self.model, self.test_loader, self.loss_function, device\n",
    "            )\n",
    "            self.test_losses.append(test_loss)\n",
    "            self.accuracies.append(accuracy)\n",
    "            self.macro_roc_aucs.append(macro_roc_auc)\n",
    "            self.micro_roc_aucs.append(micro_roc_auc)\n",
    "\n",
    "            print(f\"Epoch {epoch + 1}/{self.config['num_epochs']}, Train Loss: {train_loss:.4f}, \"\n",
    "                  f\"Test Loss: {test_loss:.4f}, Accuracy: {accuracy:.4f}, Macro ROC AUC: {macro_roc_auc:.4f}, \"\n",
    "                  f\"Micro ROC AUC: {micro_roc_auc:.4f}\")\n",
    "            \n",
    "            # Calculate confusion matrix\n",
    "            predicted_labels = np.argmax(all_outputs, axis=1)\n",
    "            cm = confusion_matrix(all_labels, predicted_labels)\n",
    "            print(\"Confusion Matrix:\", cm)\n",
    "            \n",
    "            # Save the model\n",
    "            torch.save(self.model.state_dict(), 'trained_vgg.pth')\n",
    "\n",
    "            # Calculate class-wise ROC AUC\n",
    "            all_labels_one_hot = np.eye(10)[all_labels]\n",
    "            class_roc_auc = roc_auc_score(all_labels_one_hot, all_outputs, average=None, multi_class='ovr')\n",
    "            self.class_roc_aucs.append(class_roc_auc)\n",
    "            \n",
    "            end_time = time.time()\n",
    "            epoch_time = end_time - start_time\n",
    "            print(f\"Epoch {epoch + 1} / {self.config['num_epochs']}, Time: {epoch_time:.2f} s\")"
   ],
   "id": "9debdad6f5c7e474",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4.2 Run Experiments",
   "id": "db2417c6984c3afc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define the experiment configurations\n",
    "learning_rates = [0.0001, 0.001]    # Learning rates from 0.0001 to 0.001\n",
    "batch_sizes = [32, 64]          # Batch sizes of 32 and 64\n",
    "num_epochs_list = [5, 10, 20]         # Number of epochs\n",
    "optimizers = ['adam', 'sgd']              # Adam and SGD optimizers\n",
    "augmentations = [\n",
    "    {'rotate': 30, 'scale_min': 0.8, 'scale_max': 1.0, 'min_ratio': 0.75, 'max_ratio': 1.33},\n",
    "    {'rotate': 15, 'scale_min': 0.9, 'scale_max': 1.0, 'min_ratio': 0.85, 'max_ratio': 1.23}\n",
    "]\n",
    "\n",
    "# Generate all possible experiment configurations\n",
    "experiment_configs = [\n",
    "    {\n",
    "        'learning_rate': lr,\n",
    "        'batch_size': bs,\n",
    "        'num_epochs': ne,\n",
    "        'optimizer': opt,\n",
    "        'augmentation': aug\n",
    "    }\n",
    "    for lr, bs, ne, opt, aug in product(learning_rates, batch_sizes, num_epochs_list, optimizers, augmentations)\n",
    "]\n",
    "\n",
    "# Run the experiments\n",
    "results = []\n",
    "for config in experiment_configs:\n",
    "    print(f\"Running experiment with config: {config}\")\n",
    "    runner = ExperimentRunner(config)\n",
    "    runner.train()\n",
    "    results.append(runner)\n",
    "\n",
    "# Visualize the results\n",
    "for result in results:\n",
    "    config = result.config\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    plt.suptitle(f\"Experiment Config: {config}\")\n",
    "\n",
    "    # Plot the training and test losses\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(result.train_losses, label=\"Train Loss\")\n",
    "    plt.plot(result.test_losses, label=\"Test Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training and Test Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot the accuracy and ROC AUC\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(result.accuracies, label=\"Accuracy\")\n",
    "    plt.plot(result.macro_roc_aucs, label=\"Macro ROC AUC\")\n",
    "    plt.plot(result.micro_roc_aucs, label=\"Micro ROC AUC\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Metric\")\n",
    "    plt.title(\"Accuracy and ROC AUC\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot the class-wise ROC AUC\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.bar(range(10), result.class_roc_aucs[-1])\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.ylabel(\"ROC AUC\")\n",
    "    plt.title(\"Class-wise ROC AUC\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Generate a summary of the experiments\n",
    "summary_data = []\n",
    "for result in results:\n",
    "    config = result.config\n",
    "    final_test_loss = result.test_losses[-1]\n",
    "    final_accuracy = result.accuracies[-1]\n",
    "    final_macro_roc_auc = result.macro_roc_aucs[-1]\n",
    "    final_micro_roc_auc = result.micro_roc_aucs[-1]\n",
    "    summary_data.append({\n",
    "        'Learning Rate': config['learning_rate'],\n",
    "        'Batch Size': config['batch_size'],\n",
    "        'Num Epochs': config['num_epochs'],\n",
    "        'Optimizer': config['optimizer'],\n",
    "        'Rotate': config['augmentation']['rotate'],\n",
    "        'Scale Min': config['augmentation']['scale_min'],\n",
    "        'Scale Max': config['augmentation']['scale_max'],\n",
    "        'Min Ratio': config['augmentation']['min_ratio'],\n",
    "        'Max Ratio': config['augmentation']['max_ratio'],\n",
    "        'Final Train Loss': result.train_losses[-1],\n",
    "        'Final Test Loss': final_test_loss,\n",
    "        'Final Accuracy': final_accuracy,\n",
    "        'Final Macro ROC AUC': final_macro_roc_auc,\n",
    "        'Final Micro ROC AUC': final_micro_roc_auc\n",
    "    })\n",
    "\n",
    "# Save the summary to a CSV file\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df.to_csv('experiment_summary_with_class.csv', index=False)"
   ],
   "id": "ca43acff1917c391"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Best Model Training(with the Best Configuration)",
   "id": "4e23776200424e94"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T05:24:52.056890Z",
     "start_time": "2024-11-08T05:05:29.963680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the best configuration\n",
    "best_config = {\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 64,\n",
    "    'num_epochs': 20,\n",
    "    'optimizer': 'adam',\n",
    "    'augmentation': {\n",
    "        'rotate': 15,\n",
    "        'scale_min': 0.9,\n",
    "        'scale_max': 1.0,\n",
    "        'min_ratio': 0.85,\n",
    "        'max_ratio': 1.23\n",
    "    }\n",
    "}\n",
    "\n",
    "# Train the best model\n",
    "runner = ExperimentRunner(best_config)\n",
    "runner.train()"
   ],
   "id": "3d578adbb2a295d1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jerry\\.conda\\envs\\pytorch\\lib\\site-packages\\pydantic\\main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.\n",
      "  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data\\train_32x32.mat\n",
      "Using downloaded and verified file: ./data\\test_32x32.mat\n",
      "Epoch 1/20, Train Loss: 1.9316, Test Loss: 0.9375, Accuracy: 0.7084, Macro ROC AUC: 0.9330, Micro ROC AUC: 0.9382\n",
      "Confusion Matrix: [[1431   49   39   28   21   20   35   47    9   62]\n",
      " [ 371 3614  498   42   94   26   15  392    7   30]\n",
      " [  68   79 3616   89   58   69   11   93    7   51]\n",
      " [ 110   63  275 1560   34  285   40   86   68  355]\n",
      " [ 120  117  136   30 1924   41   11   12    4  124]\n",
      " [  23   15   37  133   40 1955  100   10   19   49]\n",
      " [  99   49   35   69   84  496  966    9  119   44]\n",
      " [  43   98  126   27    4  106    5 1599    3    5]\n",
      " [ 206   32   74  220   43   95  102   20  654  211]\n",
      " [ 137   31   73   94   32   82   17   23   17 1088]]\n",
      "Epoch 1 / 20, Time: 57.38 s\n",
      "Epoch 2/20, Train Loss: 1.2936, Test Loss: 0.5198, Accuracy: 0.8486, Macro ROC AUC: 0.9716, Micro ROC AUC: 0.9719\n",
      "Confusion Matrix: [[1476   13   34   27    8   15   80    3   11   74]\n",
      " [ 156 4422  140   63  114   18   21  129   18    8]\n",
      " [   4   27 3948   55   21   25   11   36    6    8]\n",
      " [  21   36  123 2305   18  143   34    7   75  114]\n",
      " [  25   55   89   63 2168   54   14    8   11   32]\n",
      " [   5    9   32  104   15 2116   77    1    5   17]\n",
      " [  44   17   12   60   23  203 1529    2   55   25]\n",
      " [  11   66   97   29    5   36    7 1754    9    2]\n",
      " [  49   12   47  169   14   74  142    0 1080   70]\n",
      " [  56    8  124   48    8   56   15    3   25 1251]]\n",
      "Epoch 2 / 20, Time: 55.36 s\n",
      "Epoch 3/20, Train Loss: 1.0585, Test Loss: 0.4145, Accuracy: 0.8777, Macro ROC AUC: 0.9790, Micro ROC AUC: 0.9793\n",
      "Confusion Matrix: [[1540    7   21   25    2    8   63    4   10   61]\n",
      " [ 130 4552   87   66   89   15   17  115   13    5]\n",
      " [   3   20 3951   61   18   24    8   42    1   13]\n",
      " [  14   21   92 2525   14   55   25    5   31   94]\n",
      " [  27   46   69   33 2284   11    5   10    4   30]\n",
      " [   4    7   25  155   11 2069   76    3    7   24]\n",
      " [  47   19   16   51   11   85 1684    2   35   20]\n",
      " [   8   72   57   49    5   22    3 1797    0    3]\n",
      " [  54   10   36  135   10   42  217    0 1073   80]\n",
      " [  48    7  107   30   10   25   13    6   16 1332]]\n",
      "Epoch 3 / 20, Time: 56.92 s\n",
      "Epoch 4/20, Train Loss: 0.9587, Test Loss: 0.3460, Accuracy: 0.8988, Macro ROC AUC: 0.9831, Micro ROC AUC: 0.9838\n",
      "Confusion Matrix: [[1521   11    6    7    3    8   66    3   17   99]\n",
      " [  76 4768   24   45   51    9   24   72   12    8]\n",
      " [   3   31 3909   90   23   10   11   37   10   17]\n",
      " [  12   30   35 2485   14   59   27    4   85  125]\n",
      " [  19   83   29   43 2277    6   12   10    7   33]\n",
      " [   3   12   13  120    7 2073   98    2   15   38]\n",
      " [  36   19    3   31    9   42 1745    2   54   29]\n",
      " [   5   91   38   33    3   16    3 1819    6    2]\n",
      " [  34    9    8   64   10   26  121    1 1320   64]\n",
      " [  23   12   43   17    4   10   18    2   28 1437]]\n",
      "Epoch 4 / 20, Time: 56.91 s\n",
      "Epoch 5/20, Train Loss: 0.8915, Test Loss: 0.3430, Accuracy: 0.8982, Macro ROC AUC: 0.9842, Micro ROC AUC: 0.9840\n",
      "Confusion Matrix: [[1475   11   13   15    1   14   88    3   22   99]\n",
      " [  78 4714   69   62   44   19   18   67    9    9]\n",
      " [   3   21 3964   71   15   21    9   17    5   15]\n",
      " [   8   18   55 2496   11   88   18    1   40  141]\n",
      " [  13   52   47   44 2296    9   10    5    8   35]\n",
      " [   3    6   18   96    9 2174   44    2    8   21]\n",
      " [  19   19    4   30    9  100 1702    2   59   26]\n",
      " [   3   77   67   45    4   22    5 1784    5    4]\n",
      " [  23   11   16   77    9   42   93    1 1298   87]\n",
      " [  17    7   52   16    2   28   12    4   20 1436]]\n",
      "Epoch 5 / 20, Time: 57.68 s\n",
      "Epoch 6/20, Train Loss: 0.8476, Test Loss: 0.3099, Accuracy: 0.9080, Macro ROC AUC: 0.9849, Micro ROC AUC: 0.9861\n",
      "Confusion Matrix: [[1557   12   13    5    2   13   60    5   16   58]\n",
      " [  59 4768   34   31   69   17   18   83    7    3]\n",
      " [   6   21 3969   44   31   15    8   32    3   12]\n",
      " [  15   30   55 2416   19  116   18    7   83  117]\n",
      " [  16   50   29   14 2361   10    5   11    5   18]\n",
      " [   6    6   18   77   11 2172   65    2    7   17]\n",
      " [  40   18    5   22   13   64 1734    2   53   19]\n",
      " [   3   68   47   16    5   10    2 1859    3    3]\n",
      " [  43   11   13   31   13   32   98    0 1357   59]\n",
      " [  37   11   59   12    7   18   13    6   30 1401]]\n",
      "Epoch 6 / 20, Time: 57.00 s\n",
      "Epoch 7/20, Train Loss: 0.8186, Test Loss: 0.2886, Accuracy: 0.9143, Macro ROC AUC: 0.9865, Micro ROC AUC: 0.9877\n",
      "Confusion Matrix: [[1559   23    8    7    2   11   52    3   17   59]\n",
      " [  26 4870   16   33   51   13   13   55    9    3]\n",
      " [   3   37 3921   96   22   11    7   20   12   12]\n",
      " [  10   26   28 2539   15   99   16    2   48   93]\n",
      " [   8   80   18   27 2353    3    6    7    5   12]\n",
      " [   2   12    9   86    7 2181   58    3   11   12]\n",
      " [  26   20    2   28   15   64 1738    1   54   22]\n",
      " [   2  103   51   32    6   13    1 1804    1    3]\n",
      " [  27   18    7   59   14   36   77    3 1369   47]\n",
      " [  23   14   46   20    6   20    7    3   31 1424]]\n",
      "Epoch 7 / 20, Time: 57.09 s\n",
      "Epoch 8/20, Train Loss: 0.7859, Test Loss: 0.2909, Accuracy: 0.9141, Macro ROC AUC: 0.9864, Micro ROC AUC: 0.9876\n",
      "Confusion Matrix: [[1619   12    3    5    2    5   29    4    4   58]\n",
      " [  62 4844   18   20   68    9    9   47    4    8]\n",
      " [   6   38 3922   75   35    6    8   29    1   21]\n",
      " [  18   32   35 2540   23   38   18    7   22  143]\n",
      " [  18   61   16    8 2391    2    1    7    0   15]\n",
      " [   5    9   15  129   16 2103   67    2    5   30]\n",
      " [  52   16    4   23   17   32 1778    1   19   28]\n",
      " [   4   87   35   28   10    8    2 1835    0    7]\n",
      " [  62   11    7   51   22   20  119    1 1259  105]\n",
      " [  36   16   34   13    9    8   10    3    5 1460]]\n",
      "Epoch 8 / 20, Time: 57.35 s\n",
      "Epoch 9/20, Train Loss: 0.7734, Test Loss: 0.2826, Accuracy: 0.9160, Macro ROC AUC: 0.9875, Micro ROC AUC: 0.9883\n",
      "Confusion Matrix: [[1637   15    5    2    1    5   38    5    3   30]\n",
      " [  54 4878   18   14   44   11    7   54    6    3]\n",
      " [   8   43 3924   62   23   14   11   42    1   13]\n",
      " [  26   48   30 2462   21   82   20   12   31  144]\n",
      " [  19   80   11    9 2362    4    5   12    1   16]\n",
      " [   7   16   11   62    8 2161   83    3    6   24]\n",
      " [  51   16    3   15   11   33 1800    3   21   17]\n",
      " [   5   75   27   12    8   13    2 1869    1    4]\n",
      " [  89   14    8   25   19   21  148    0 1285   48]\n",
      " [  64   14   45    7    4   11   12    2   12 1423]]\n",
      "Epoch 9 / 20, Time: 57.30 s\n",
      "Epoch 10/20, Train Loss: 0.7518, Test Loss: 0.2751, Accuracy: 0.9207, Macro ROC AUC: 0.9884, Micro ROC AUC: 0.9887\n",
      "Confusion Matrix: [[1558   15    5    3    1    5   70    4   18   62]\n",
      " [  52 4846   18   32   45   10   25   44   12    5]\n",
      " [   5   29 3884  109   21   10   13   37   16   17]\n",
      " [   9   21   21 2568   10   59   20    2   86   80]\n",
      " [  14   63   16   12 2370    4    7    7    8   18]\n",
      " [   3    6    7   79    5 2166   77    2   17   19]\n",
      " [  26   12    2   13    5   24 1816    2   51   19]\n",
      " [   4   80   36   38    8   15    6 1826    1    2]\n",
      " [  31    9    5   13   11   20   99    0 1428   41]\n",
      " [  27   11   26   12    5    7    9    3   32 1462]]\n",
      "Epoch 10 / 20, Time: 55.96 s\n",
      "Epoch 11/20, Train Loss: 0.7361, Test Loss: 0.2606, Accuracy: 0.9236, Macro ROC AUC: 0.9891, Micro ROC AUC: 0.9898\n",
      "Confusion Matrix: [[1592   10    4    4    1    6   51    3   12   58]\n",
      " [  53 4816   36   20   73   10   17   49   10    5]\n",
      " [   4   26 3982   40   28    7   11   30    1   12]\n",
      " [  10   30   38 2547   19   46   25    4   45  112]\n",
      " [   9   40   23    8 2400    4    8    9    3   15]\n",
      " [   3    9   11   71    8 2172   82    2    6   17]\n",
      " [  26   14    4   12   17   26 1819    3   31   18]\n",
      " [   3   77   42   21    5    7    1 1856    1    3]\n",
      " [  43    8   10   24   21   19  116    1 1357   58]\n",
      " [  24    7   40   12    9    8   11    2   24 1457]]\n",
      "Epoch 11 / 20, Time: 63.85 s\n",
      "Epoch 12/20, Train Loss: 0.7240, Test Loss: 0.2643, Accuracy: 0.9224, Macro ROC AUC: 0.9892, Micro ROC AUC: 0.9900\n",
      "Confusion Matrix: [[1629   11    3    2    1    7   27    3    7   51]\n",
      " [  84 4846   17   19   48   11   18   33    9    4]\n",
      " [   5   29 3975   44   24   11   12   16   10   15]\n",
      " [  16   26   25 2514   14   63   19    5   57  137]\n",
      " [  18   39   17    7 2389    4   15    6    5   19]\n",
      " [   4    8   10   52    8 2181   86    2   11   19]\n",
      " [  53   13    1   14    9   24 1801    2   37   16]\n",
      " [   5  134   33   15    9   12    4 1794    4    6]\n",
      " [  54    8    6   15   13   16  109    0 1381   55]\n",
      " [  34   10   38   11    4    5    8    1   26 1457]]\n",
      "Epoch 12 / 20, Time: 64.92 s\n",
      "Epoch 13/20, Train Loss: 0.7168, Test Loss: 0.2469, Accuracy: 0.9290, Macro ROC AUC: 0.9903, Micro ROC AUC: 0.9910\n",
      "Confusion Matrix: [[1596   15    5    3    2    9   37    4   10   60]\n",
      " [  36 4892   19   19   54   13   13   35    6    2]\n",
      " [   3   34 3975   42   24   13    8   26    1   15]\n",
      " [   8   24   27 2584    8   84   13    3   18  107]\n",
      " [   9   48   17    7 2396    7    5    8    3   19]\n",
      " [   4    8    9   40    9 2250   35    3    7   16]\n",
      " [  34   15    2   17   10   63 1767    2   43   17]\n",
      " [   4  104   37   19    7   12    2 1827    1    3]\n",
      " [  33   13    9   29   14   36   61    1 1379   82]\n",
      " [  24   10   34   12    5   14    4    4   15 1472]]\n",
      "Epoch 13 / 20, Time: 61.03 s\n",
      "Epoch 14/20, Train Loss: 0.7038, Test Loss: 0.2480, Accuracy: 0.9280, Macro ROC AUC: 0.9904, Micro ROC AUC: 0.9911\n",
      "Confusion Matrix: [[1605   10    7    4    0    7   45    4   14   45]\n",
      " [  63 4846   29   26   51    9   16   38    7    4]\n",
      " [   4   28 3989   44   24    7   10   21    1   13]\n",
      " [  14   26   35 2559   12   54   14    3   30  129]\n",
      " [  11   33   23   12 2400    6    5    4    3   22]\n",
      " [   4    6   18   67    8 2204   42    2    9   21]\n",
      " [  32   13    4   17    7   34 1799    2   40   22]\n",
      " [   5  108   32   25    8   11    3 1819    2    3]\n",
      " [  36    9    8   26   10   21   68    1 1428   50]\n",
      " [  25    8   48   12    3    7    7    3   16 1465]]\n",
      "Epoch 14 / 20, Time: 56.77 s\n",
      "Epoch 15/20, Train Loss: 0.6967, Test Loss: 0.2536, Accuracy: 0.9268, Macro ROC AUC: 0.9897, Micro ROC AUC: 0.9904\n",
      "Confusion Matrix: [[1600   11    6    3    1    5   35    3   11   66]\n",
      " [  55 4873   26   24   47    8   13   28   10    5]\n",
      " [   5   31 3976   45   23    5    9   30    1   16]\n",
      " [  19   31   25 2525   19   80   15    6   39  117]\n",
      " [  13   45   16    8 2395    4    4    7    5   22]\n",
      " [   4    7   15   50    9 2209   62    2    4   19]\n",
      " [  38   14    6   11    8   25 1806    2   41   19]\n",
      " [   8  134   27   16    6    9    3 1806    4    3]\n",
      " [  45    9    7   21   14   21   85    0 1415   40]\n",
      " [  28    7   30   11    3    8   10    3   17 1477]]\n",
      "Epoch 15 / 20, Time: 57.46 s\n",
      "Epoch 16/20, Train Loss: 0.6870, Test Loss: 0.2462, Accuracy: 0.9291, Macro ROC AUC: 0.9905, Micro ROC AUC: 0.9910\n",
      "Confusion Matrix: [[1642   13    3    4    0    6   26    3    9   35]\n",
      " [  59 4896   14   24   43    7   12   23    8    3]\n",
      " [   7   45 3923   76   18   10   10   26    6   20]\n",
      " [  14   31   16 2583   11   61   17    5   30  108]\n",
      " [  15   61   12   14 2381    2    8   10    1   15]\n",
      " [   5   10    7   67    5 2208   52    3    6   18]\n",
      " [  34   13    2   17    6   34 1826    2   26   10]\n",
      " [   8  132   26   19    4    9    3 1811    0    4]\n",
      " [  38    7    4   23   10   20  109    1 1410   35]\n",
      " [  37   14   26   10    4    7    7    2   25 1462]]\n",
      "Epoch 16 / 20, Time: 57.32 s\n",
      "Epoch 17/20, Train Loss: 0.6782, Test Loss: 0.2358, Accuracy: 0.9319, Macro ROC AUC: 0.9906, Micro ROC AUC: 0.9913\n",
      "Confusion Matrix: [[1605   12    8    2    1    8   34    3   20   48]\n",
      " [  41 4844   27   37   57   13   12   42   11    5]\n",
      " [   5   23 3980   58   21    6    5   24    4   15]\n",
      " [   9   16   21 2619   12   54   10    3   32  100]\n",
      " [  10   28   18    9 2420    3    3    6    3   19]\n",
      " [   3    7   14   86    8 2204   32    2    8   17]\n",
      " [  30   12    3   24    8   41 1764    2   64   22]\n",
      " [   4   81   33   30   10    9    3 1839    4    3]\n",
      " [  30    6    5   30   15   23   55    0 1449   44]\n",
      " [  17    4   35   13    5    8    7    3   11 1491]]\n",
      "Epoch 17 / 20, Time: 57.32 s\n",
      "Epoch 18/20, Train Loss: 0.6846, Test Loss: 0.2288, Accuracy: 0.9335, Macro ROC AUC: 0.9913, Micro ROC AUC: 0.9919\n",
      "Confusion Matrix: [[1634   10    6    3    1    4   30    3   17   33]\n",
      " [  49 4868   19   25   41   10   11   49   11    6]\n",
      " [   7   30 3950   66   22    9    8   27    6   16]\n",
      " [  13   21   17 2618    7   46   12    4   33  105]\n",
      " [  14   43   12    8 2402    2    3   10    4   21]\n",
      " [   4    8   11   66    7 2184   68    2   13   18]\n",
      " [  37   12    2   15    7   15 1814    3   57    8]\n",
      " [   5   91   26   25    5   10    1 1847    1    5]\n",
      " [  34    5    4   17   11   12   75    2 1464   33]\n",
      " [  29    5   33   10    3    8    4    4   23 1475]]\n",
      "Epoch 18 / 20, Time: 57.38 s\n",
      "Epoch 19/20, Train Loss: 0.6723, Test Loss: 0.2384, Accuracy: 0.9288, Macro ROC AUC: 0.9913, Micro ROC AUC: 0.9918\n",
      "Confusion Matrix: [[1651   16    4    3    1    3   30    2    6   25]\n",
      " [  56 4907   10   15   47    8   13   25    6    2]\n",
      " [   8   49 3946   48   35    7   10   24    1   13]\n",
      " [  15   41   27 2551   17   55   20    3   25  122]\n",
      " [  10   53   13    7 2410    1    3    6    2   14]\n",
      " [   9   12    6   58   10 2192   74    1    2   17]\n",
      " [  50   14    2   13   14   19 1829    2   20    7]\n",
      " [   4  134   19   17    5    6    2 1825    0    4]\n",
      " [  57   13    6   25   13   15  118    1 1358   51]\n",
      " [  43   13   30   10    5    9    5    3   10 1466]]\n",
      "Epoch 19 / 20, Time: 57.57 s\n",
      "Epoch 20/20, Train Loss: 0.6692, Test Loss: 0.2279, Accuracy: 0.9341, Macro ROC AUC: 0.9919, Micro ROC AUC: 0.9922\n",
      "Confusion Matrix: [[1657    7    5    2    0    4   23    3   13   27]\n",
      " [  92 4808   21   41   54   10   16   33    9    5]\n",
      " [  10   33 3945   69   23    7   10   28    5   11]\n",
      " [  13   15   13 2651    7   46   17    0   29   85]\n",
      " [  12   25   12   10 2428    4    6    3    5   14]\n",
      " [   4    5    8   68    5 2183   75    2   13   18]\n",
      " [  37    9    1   10    7   17 1835    3   43    8]\n",
      " [   8  101   22   35    6   10    3 1824    2    5]\n",
      " [  39    5    4   16   11   11   72    0 1469   30]\n",
      " [  37    5   31   12    4    8    4    1   20 1472]]\n",
      "Epoch 20 / 20, Time: 57.34 s\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 6. Model Deployment with Gradio",
   "id": "8427e975d88dfb6c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T05:24:56.814279Z",
     "start_time": "2024-11-08T05:24:52.056890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the best model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = VGG().to(device)\n",
    "state_dict = torch.load('best_trained_vgg.pth', map_location=device)\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model.eval()\n",
    "\n",
    "# Define the preprocessing function\n",
    "def preprocess_image(image):\n",
    "    try:\n",
    "        # Print the type and keys of the received image\n",
    "        print(f\"Received image data type: {type(image)}\")\n",
    "        if isinstance(image, dict):\n",
    "            print(f\"Received image keys: {image.keys()}\")\n",
    "            image = image.get('composite')  # Extract the image from the dictionary\n",
    "            print(f\"Extracted image data type: {type(image)}\")\n",
    "            print(f\"Extracted image shape: {image.shape if isinstance(image, np.ndarray) else 'Not a numpy array'}\")\n",
    "\n",
    "        if not isinstance(image, np.ndarray):\n",
    "            print(\"Image is not a numpy array after extraction.\")\n",
    "            return None\n",
    "\n",
    "        # Convert the image to a PIL Image\n",
    "        image = Image.fromarray(np.uint8(image)).convert(\"RGBA\")\n",
    "\n",
    "        # Create a white background\n",
    "        white_background = Image.new(\"RGB\", image.size, (255, 255, 255))\n",
    "\n",
    "        # Paste the image on the white background\n",
    "        white_background.paste(image, mask=image.split()[3])  # Use the alpha channel for masking\n",
    "\n",
    "        # Convert the image to a numpy array\n",
    "        image = np.array(white_background)\n",
    "\n",
    "        # Save the original input image with a white background\n",
    "        Image.fromarray(np.uint8(image)).save('original_input_image_with_white_background.png')\n",
    "\n",
    "        # Resize and transform the image to a tensor\n",
    "        resized_image = Image.fromarray(image).resize((32, 32))  # Resize to 32x32\n",
    "        resized_image = np.array(resized_image)\n",
    "        transformed = torch.tensor(resized_image).permute(2, 0, 1).unsqueeze(0).float().to(device)\n",
    "\n",
    "        # Save the preprocessed image\n",
    "        torchvision.utils.save_image(transformed / 255.0, 'preprocessed_image_without_norm.png')  \n",
    "\n",
    "        return transformed\n",
    "    except Exception as e:\n",
    "        print(f\"Error during preprocessing: {e}\")\n",
    "        return None\n",
    "\n",
    "# Define the preprocessing function\n",
    "def classify_digit(sketchpad_image):\n",
    "    # Choose non null image\n",
    "    image = sketchpad_image\n",
    "    if image is None:\n",
    "        return \"No image provided.\"\n",
    "\n",
    "    img_tensor = preprocess_image(image)\n",
    "    if img_tensor is None:\n",
    "        return \"Error during preprocessing.\"\n",
    "\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            output = model(img_tensor)  # Run the model\n",
    "            probabilities = torch.softmax(output, dim=1).cpu().numpy()[0]\n",
    "        return {str(i): float(probabilities[i]) for i in range(10)}\n",
    "    except Exception as e:\n",
    "        print(f\"Error during classification: {e}\")\n",
    "        return \"Error during classification.\"\n",
    "\n",
    "# Create a Gradio interface\n",
    "sketchpad = gr.Sketchpad()\n",
    "interface = gr.Interface(\n",
    "    fn=classify_digit,\n",
    "    inputs=sketchpad,\n",
    "    outputs=\"label\",\n",
    "    live=True\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "interface.launch(share=True)"
   ],
   "id": "4d419b77d19743d4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jerry\\AppData\\Local\\Temp\\ipykernel_7316\\3424629127.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load('best_trained_vgg.pth', map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://8d1157014dd33dc1e0.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div><iframe src=\"https://8d1157014dd33dc1e0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1e353f2886776015"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
